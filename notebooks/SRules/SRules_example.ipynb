{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from notebooks.SRules.read_datasets import read_dataset\n",
    "\n",
    "filename = \"salud-covid\"\n",
    "#filename = \"divorce\"\n",
    "test_size=0.1\n",
    "path = f'../..'\n",
    "dataset_path_name = f'{path}/data/{filename}.csv'\n",
    "X, y, dataset, target_value_name, pandas_dataset = read_dataset(filename, dataset_path_name)\n",
    "\n",
    "pandas_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Define dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=test_size, random_state=1)\n",
    "encoded_train_pandas_dataset = pd.DataFrame(data= np.c_[X_train, y_train], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "encoded_test_pandas_dataset = pd.DataFrame(data= np.c_[X_test, y_test], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "print('Sizes (without target):')\n",
    "print(f'Original size {dataset.data.shape}')\n",
    "print(f'Train size {X_train.shape}')\n",
    "print(f'Test size {X_test.shape}')\n",
    "print(f'encoded_train_pandas_dataset size {encoded_train_pandas_dataset.shape}')\n",
    "print(f'encoded_test_pandas_dataset size {encoded_test_pandas_dataset.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, make_scorer, recall_score, accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Define scorer\n",
    "ensemble = SVC()\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from SRules.SRules import SRules\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "rules = SRules(\n",
    "                feature_names=dataset.feature_names,\n",
    "                target_value_name = dataset.target_names,\n",
    "                display_features = False,\n",
    "                display_logs = False,\n",
    "                recursive=True,\n",
    "                chi_square_percent_point_function = 0.99,\n",
    "                scale_feature_coefficient = 0.01,\n",
    "                min_accuracy_coefficient = 0.95,\n",
    "                min_number_class_per_node = 5\n",
    "            )\n",
    "# Fit model\n",
    "rules.fit(\n",
    "    method=ensemble,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    original_dataset=encoded_train_pandas_dataset,\n",
    "    use_shap=True)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed TOTAL TIME: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ENSEMBLE\n",
    "y_pred_test_ensemble = ensemble.predict(X_test)\n",
    "\n",
    "# RULES\n",
    "y_pred_test_rules = rules.predict(X_test, sorting_method=\"target_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# CATEGORIZABLES\n",
    "np_array_rules = np.array(y_pred_test_rules)\n",
    "#not_filter_indices = np.where(np.logical_and(np_array_rules != 0, np_array_rules!=1))[0]\n",
    "filter_indices = np.where(np_array_rules != None)[0]\n",
    "\n",
    "\n",
    "np_filterred_y_test = np.array(y_test)[filter_indices]\n",
    "np_filterred_y_pred_test_ensemble = np.array(y_pred_test_ensemble)[filter_indices]\n",
    "np_filterred_y_pred_test_rules = np.array(y_pred_test_rules)[filter_indices]\n",
    "# CHANGE FORMAT IN ORDER TO NOT HAVE PROBLEMS\n",
    "np_filterred_y_pred_test_rules = np_filterred_y_pred_test_rules.astype('int64')\n",
    "\n",
    "\n",
    "print(f'DATASET TEST: {len(y_test)}')\n",
    "print(f'DATASET TEST categorizable: {len(np_filterred_y_test)}')\n",
    "print('Cobertura:',str(\"{:.2f}\".format(100*(len(np_filterred_y_pred_test_rules)/len(y_test))))+'%')\n",
    "\n",
    "ensemble_accuracy = metrics.accuracy_score(np_filterred_y_test, np_filterred_y_pred_test_ensemble)\n",
    "print('RF accuracy:',str(\"{:.2f}\".format(100*ensemble_accuracy))+'%')\n",
    "ensemble_accuracy = metrics.f1_score(np_filterred_y_test, np_filterred_y_pred_test_ensemble)\n",
    "print('RF F1-score:',str(\"{:.2f}\".format(100*ensemble_accuracy))+'%')\n",
    "rules_accuracy = metrics.accuracy_score(np_filterred_y_test, np_filterred_y_pred_test_rules)\n",
    "print('Rules Accuracy:',str(\"{:.2f}\".format(100*rules_accuracy))+'%')\n",
    "rules_F1 = metrics.f1_score(np_filterred_y_test, np_filterred_y_pred_test_rules)\n",
    "print('Rules F1-score:',str(\"{:.2f}\".format(100*rules_F1))+'%')\n",
    "rules_roc_auc = metrics.roc_auc_score(np_filterred_y_test, np_filterred_y_pred_test_rules)\n",
    "print('Rules roc_auc_score:',str(\"{:.2f}\".format(100*rules_roc_auc))+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(ensemble))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create Tree Explainer object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(ensemble)\n",
    "\n",
    "# Evaluate SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_train, feature_names=dataset.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def print_feature_importances_shap_values(shap_values, features):\n",
    "    '''\n",
    "    Prints the feature importances based on SHAP values in an ordered way\n",
    "    shap_values -> The SHAP values calculated from a shap.Explainer object\n",
    "    features -> The name of the features, on the order presented to the explainer\n",
    "    '''\n",
    "    # Calculates the feature importance (mean absolute shap value) for each feature\n",
    "    importances = []\n",
    "    for i in range(shap_values.values.shape[1]):\n",
    "        importances.append(np.mean(np.abs(shap_values.values[:, i])))\n",
    "    # Calculates the normalized version\n",
    "    importances_norm = softmax(importances)\n",
    "    # Organize the importances and columns in a dictionary\n",
    "    feature_importances = {fea: imp for imp, fea in zip(importances, features)}\n",
    "    feature_importances_norm = {fea: imp for imp, fea in zip(importances_norm, features)}\n",
    "    # Sorts the dictionary\n",
    "    feature_importances = {k: v for k, v in sorted(feature_importances.items(), key=lambda item: item[1], reverse = True)}\n",
    "    feature_importances_norm= {k: v for k, v in sorted(feature_importances_norm.items(), key=lambda item: item[1], reverse = True)}\n",
    "    # Prints the feature importances\n",
    "    for k, v in feature_importances.items():\n",
    "        print(f\"{k} -> {v:.4f} (softmax = {feature_importances_norm[k]:.4f})\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate SHAP values\n",
    "shap_values = explainer(X_test)\n",
    "print_feature_importances_shap_values(shap_values,dataset.feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, plot_type='violin')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
