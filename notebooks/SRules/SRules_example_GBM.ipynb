{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:02:29.877894Z",
     "start_time": "2023-08-15T19:02:26.278977Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:02:31.067741Z",
     "start_time": "2023-08-15T19:02:29.879932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Atr1_0  Atr1_1  Atr1_2  Atr1_3  Atr1_4  Atr2_0  Atr2_1  Atr2_2  Atr2_3  \\\n0   False   False    True   False   False   False   False    True   False   \n1   False   False   False   False    True   False   False   False   False   \n2   False   False    True   False   False   False   False    True   False   \n3   False   False   False    True   False   False   False    True   False   \n4   False   False    True   False   False   False   False    True   False   \n\n   Atr2_4  ...  Atr53_1  Atr53_2  Atr53_3  Atr53_4  Atr54_0  Atr54_1  Atr54_2  \\\n0   False  ...    False     True    False    False    False     True    False   \n1    True  ...    False     True    False    False    False    False     True   \n2   False  ...    False     True    False    False    False    False     True   \n3   False  ...    False     True    False    False    False    False     True   \n4   False  ...     True    False    False    False     True    False    False   \n\n   Atr54_3  Atr54_4  Class  \n0    False    False   True  \n1    False    False   True  \n2    False    False   True  \n3    False    False   True  \n4    False    False   True  \n\n[5 rows x 271 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Atr1_0</th>\n      <th>Atr1_1</th>\n      <th>Atr1_2</th>\n      <th>Atr1_3</th>\n      <th>Atr1_4</th>\n      <th>Atr2_0</th>\n      <th>Atr2_1</th>\n      <th>Atr2_2</th>\n      <th>Atr2_3</th>\n      <th>Atr2_4</th>\n      <th>...</th>\n      <th>Atr53_1</th>\n      <th>Atr53_2</th>\n      <th>Atr53_3</th>\n      <th>Atr53_4</th>\n      <th>Atr54_0</th>\n      <th>Atr54_1</th>\n      <th>Atr54_2</th>\n      <th>Atr54_3</th>\n      <th>Atr54_4</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 271 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from notebooks.SRules.read_datasets import read_dataset\n",
    "\n",
    "filename = \"divorce\"\n",
    "test_size=0.1\n",
    "path = f'../..'\n",
    "dataset_path_name = f'{path}/data/{filename}.csv'\n",
    "X, y, dataset, target_value_name, pandas_dataset = read_dataset(filename, dataset_path_name)\n",
    "\n",
    "pandas_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes (without target):\n",
      "Original size (170, 270)\n",
      "Train size (153, 270)\n",
      "Test size (17, 270)\n",
      "encoded_train_pandas_dataset size (153, 271)\n",
      "encoded_test_pandas_dataset size (17, 271)\n"
     ]
    }
   ],
   "source": [
    "#Define dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=test_size, random_state=1)\n",
    "encoded_train_pandas_dataset = pd.DataFrame(data= np.c_[X_train, y_train], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "encoded_test_pandas_dataset = pd.DataFrame(data= np.c_[X_test, y_test], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "print('Sizes (without target):')\n",
    "print(f'Original size {dataset.data.shape}')\n",
    "print(f'Train size {X_train.shape}')\n",
    "print(f'Test size {X_test.shape}')\n",
    "print(f'encoded_train_pandas_dataset size {encoded_train_pandas_dataset.shape}')\n",
    "print(f'encoded_test_pandas_dataset size {encoded_test_pandas_dataset.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T19:02:31.121078Z",
     "start_time": "2023-08-15T19:02:31.053058Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-15T19:02:31.098012Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, make_scorer, recall_score, accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Define scorer\n",
    "ensemble = LGBMClassifier()\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from SRules.SRules import SRules\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "rules = SRules(\n",
    "                feature_names=dataset.feature_names,\n",
    "                target_value_name = dataset.target_names,\n",
    "                display_features = True,\n",
    "                display_logs = True,\n",
    "                chi_square_percent_point_function = 0.99,\n",
    "                scale_feature_coefficient = 0.1,\n",
    "                min_accuracy_coefficient = 0.95,\n",
    "                min_number_class_per_node = 5\n",
    "            )\n",
    "# Fit model\n",
    "rules.fit(ensemble, X_train, y_train, encoded_train_pandas_dataset, ensemble.feature_importances_)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed TOTAL TIME: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ENSEMBLE\n",
    "y_pred_test_ensemble = ensemble.predict(X_test)\n",
    "\n",
    "# RULES\n",
    "y_pred_test_rules = rules.predict(X_test, sorting_method=\"target_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# CATEGORIZABLES\n",
    "np_array_rules = np.array(y_pred_test_rules)\n",
    "#not_filter_indices = np.where(np.logical_and(np_array_rules != 0, np_array_rules!=1))[0]\n",
    "filter_indices = np.where(np_array_rules != None)[0]\n",
    "\n",
    "\n",
    "np_filterred_y_test = np.array(y_test)[filter_indices]\n",
    "np_filterred_y_pred_test_ensemble = np.array(y_pred_test_ensemble)[filter_indices]\n",
    "np_filterred_y_pred_test_rules = np.array(y_pred_test_rules)[filter_indices]\n",
    "# CHANGE FORMAT IN ORDER TO NOT HAVE PROBLEMS\n",
    "np_filterred_y_pred_test_rules = np_filterred_y_pred_test_rules.astype('int64')\n",
    "\n",
    "\n",
    "print(f'DATASET TEST: {len(y_test)}')\n",
    "print(f'DATASET TEST categorizable: {len(np_filterred_y_test)}')\n",
    "print('Cobertura:',str(\"{:.2f}\".format(100*(len(np_filterred_y_pred_test_rules)/len(y_test))))+'%')\n",
    "\n",
    "ensemble_accuracy = metrics.accuracy_score(np_filterred_y_test, np_filterred_y_pred_test_ensemble)\n",
    "print('RF accuracy:',str(\"{:.2f}\".format(100*ensemble_accuracy))+'%')\n",
    "ensemble_accuracy = metrics.f1_score(np_filterred_y_test, np_filterred_y_pred_test_ensemble)\n",
    "print('RF F1-score:',str(\"{:.2f}\".format(100*ensemble_accuracy))+'%')\n",
    "rules_accuracy = metrics.accuracy_score(np_filterred_y_test, np_filterred_y_pred_test_rules)\n",
    "print('Rules Accuracy:',str(\"{:.2f}\".format(100*rules_accuracy))+'%')\n",
    "rules_F1 = metrics.f1_score(np_filterred_y_test, np_filterred_y_pred_test_rules)\n",
    "print('Rules F1-score:',str(\"{:.2f}\".format(100*rules_F1))+'%')\n",
    "rules_roc_auc = metrics.roc_auc_score(np_filterred_y_test, np_filterred_y_pred_test_rules)\n",
    "print('Rules roc_auc_score:',str(\"{:.2f}\".format(100*rules_roc_auc))+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(ensemble))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create Tree Explainer object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(ensemble)\n",
    "\n",
    "# Evaluate SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_train, feature_names=dataset.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "shap.summary_plot(shap_values, X_train, feature_names=dataset.feature_names, plot_type=\"dot\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
